{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CapsNet \n",
    "*By Danny Luo*\n",
    "\n",
    "Implementation of capsules network model on MNIST in PyTorch (heavily) based on GramAI's implementation by Kenta Iwasaki and subsequent versions. CUDA disabled by default.\n",
    "\n",
    "This notebook offers further explanation and annotation to offer the user a deep understanding of capsules machinery.\n",
    "\n",
    "*Capsules Paper*:\n",
    "* Sara Sabour, Nicholas Frosst, and Geoffrey E. Hinton *Dynamic Routing Between Capsules*\n",
    "\n",
    "*References*\n",
    "* https://gist.github.com/kendricktan/9a776ec6322abaaf03cc9befd35508d4 \n",
    "* https://github.com/gram-ai/capsule-networks\n",
    "* https://github.com/naturomics/CapsNet-Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(15000)\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = MNIST(root='./data', download=True, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squash(t):\n",
    "    \"\"\"\n",
    "    Squash Function - Eq (1)\n",
    "    \"\"\"\n",
    "    t_norm = torch.norm(t)\n",
    "    return t_norm**2 / (1 + t_norm ** 2) * t / t_norm\n",
    "\n",
    "\n",
    "def softmax(input, dim=1):\n",
    "    \"\"\"\n",
    "    Softmax along specific dimensions\n",
    "    \"\"\"\n",
    "    transposed_input = input.transpose(dim, len(input.size()) - 1)\n",
    "    softmaxed_output = F.softmax(transposed_input.contiguous().view(-1, transposed_input.size(-1)))\n",
    "    return softmaxed_output.view(*transposed_input.size()).transpose(dim, len(input.size()) - 1)\n",
    "\n",
    "def index_to_one_hot(index_tensor, num_classes=10):\n",
    "    \"\"\"\n",
    "    Converts index value to one hot vector.\n",
    "\n",
    "    e.g. [2, 5] (with 10 classes) becomes:\n",
    "        [\n",
    "            [0 0 1 0 0 0 0 0 0 0]\n",
    "            [0 0 0 0 1 0 0 0 0 0]\n",
    "        ]\n",
    "    \"\"\"\n",
    "    index_tensor = index_tensor.long()\n",
    "    return torch.eye(num_classes).index_select(dim=0, index=index_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CapsNet Architecture\n",
    "\n",
    "MNIST Input: (N, 1, 28, 28), where N is the batch size. 28 x 28 is the pixel dimensions of MNIST.\n",
    "\n",
    "1. **Conv1**: 256, 9 x 9 2D convolution kernels with stride 1 (28 -> 20), ReLU. Output: (N, 256, 20, 20)\n",
    "2. **PrimaryCaps**: 32 channels of convolutional 8D capsules, each capsule contains 8 convolutional units with 9 x 9 kernel and stride 2 (20 -> 6) . Output: (N, 32 \\* 6 \\* 6 = 1152, 8). 1152 number of $u_i$'s.\n",
    "\n",
    "     *Routing between PrimaryCaps and DigitCaps.*\n",
    "     \n",
    "3. **DigitCaps**: One 16D capsule for each digit class. 10 number of $v_j$'s. Output: (N, 10, 16)\n",
    "    \n",
    "    #### Decoder\n",
    "     \n",
    "4. FC ReLU (size 512) -> FC ReLU (size 1024) -> FC Sigmoid (size 784) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CapsuleLayer(nn.Module):\n",
    "    def __init__(self, num_capsules, in_channels, out_channels, num_routings, kernel_size=3, stride=1, num_routing_iterations=5):\n",
    "            super().__init__()\n",
    "            self.num_capsules = num_capsules\n",
    "            self.in_channels = in_channels\n",
    "            self.out_channels = out_channels\n",
    "            \n",
    "            self.num_routings = num_routings\n",
    "            self.num_routing_iterations = num_routing_iterations\n",
    "            \n",
    "            # If num_routings = -1, then it is the first capsules layer\n",
    "            if num_routings == -1:\n",
    "                self.capsules = nn.ModuleList(\n",
    "                    [nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=0) for capsule in range(num_capsules)])\n",
    "            \n",
    "            else:\n",
    "                #Initialize Weights W_ij which is 8 (in) x 16 (out) matrix for each i in (1, num_routings=32x6x6=1152) and j in (1, num_classes=10)\n",
    "                self.weights = nn.Parameter(torch.randn(num_capsules, num_routings, in_channels, out_channels))\n",
    "            \n",
    "            \n",
    "    # Procedure 1: Routing algorithm. \n",
    "    def forward(self, x):\n",
    "        if self.num_routings == -1:\n",
    "            # Primary layer\n",
    "            outputs = [capsule(x).view(x.size(0), -1, 1) for capsule in self.capsules] # view = reshape, flattened 32 channels 2DConv output to vector\n",
    "            outputs = torch.cat(outputs, dim=-1) # Concatenating outputs of multiple 2D conv layers\n",
    "            outputs = squash(outputs)\n",
    "            \n",
    "        else:\n",
    "            # Procedure 1: Routing By Agreement\n",
    "            # http://pytorch.org/docs/master/torch.html?highlight=matmul#torch.matmul\n",
    "            \n",
    "            #Input Prediction Vectors u_j|i Eq. 2\n",
    "            # None adds an extra index at the selected spot | x dim (1, _, _, 1, _) |  W dim (_, 1, _, _, _)\n",
    "            \n",
    "            # x:  torch.Size([1, 4, 1152, 1, 8])\n",
    "            # W:  torch.Size([10, 1, 1152, 8, 16])\n",
    "            # priors:  torch.Size([10, 4, 1152, 1, 16])\n",
    "            \n",
    "            pred = x[None, :, :, None, :].matmul(self.weights[:, None, :, :, :]) # \"prediction vectors\" u_j|i\n",
    "            \n",
    "            logits = Variable(torch.zeros(*pred.size())) #b_ij\n",
    "            \n",
    "            for i in range(self.num_routing_iterations): #\n",
    "                cc = softmax(logits, dim=2) #coupling coefficients\n",
    "                outputs = squash((cc * pred).sum(dim=2, keepdim=True))\n",
    "\n",
    "                delta_logits = (pred * outputs).sum(dim=-1, keepdim=True)\n",
    "                logits = logits + delta_logits\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CapsNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=9, stride=1)\n",
    "        self.primarycaps = CapsuleLayer(num_capsules=8, num_routings=-1, in_channels=256, out_channels=32,\n",
    "                                             kernel_size=9, stride=2)\n",
    "        self.digitcaps = CapsuleLayer(num_capsules=10, num_routings=32 * 6 * 6, in_channels=8,\n",
    "                                           out_channels=16)\n",
    "        \n",
    "        # Check below\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16 * NUM_CLASSES, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        \n",
    "        #1:  torch.Size([4, 1, 28, 28]) \n",
    "        #2:  torch.Size([4, 256, 20, 20]) \n",
    "        #3:  torch.Size([4, 1152, 8])\n",
    "        #4:  torch.Size([4, 10, 16])\n",
    "       \n",
    "        #1\n",
    "        x = F.relu(self.conv1(x), inplace=True) #F is torch function\n",
    "        x = self.primarycaps(x)\n",
    "        x = self.digitcaps(x).squeeze().transpose(0, 1) #squeeze removes all 1d, transpose dim 1 and 2\n",
    "        #4\n",
    "    \n",
    "        classes = (x ** 2).sum(dim=-1) ** 0.5 # Sums along Capsule dimension (16)\n",
    "        classes = F.softmax(classes)\n",
    "    \n",
    "        if y is None:\n",
    "            # In all batches, get the most active capsule.\n",
    "            _, max_length_indices = classes.max(dim=1) # maxs, indices = torch.max(x, [dim])\n",
    "            y = Variable(torch.sparse.torch.eye(NUM_CLASSES)).index_select(dim=0, index=max_length_indices.data)\n",
    "    \n",
    "        reconstructions = self.decoder((x * y[:, :, None]).view(x.size(0), -1))\n",
    "        print(reconstructions.size())\n",
    "        return classes, reconstructions\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capsule Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CapsuleLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CapsuleLoss, self).__init__()\n",
    "        self.reconstruction_loss = nn.MSELoss(size_average=False)\n",
    "\n",
    "    def forward(self, images, labels, classes, reconstructions):\n",
    "        left = F.relu(0.9 - classes, inplace=True) ** 2 # Here ReLU is complicated way of saying max(0, ...), as in the paper\n",
    "        right = F.relu(classes - 0.1, inplace=True) ** 2\n",
    "\n",
    "        margin_loss = labels * left + 0.5 * (1. - labels) * right\n",
    "        margin_loss = margin_loss.sum()\n",
    "\n",
    "        reconstruction_loss = self.reconstruction_loss(reconstructions, images)\n",
    "\n",
    "        return (margin_loss + 0.0005 * reconstruction_loss) / images.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Loading Data\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    MNIST(root='/tmp', download=True, train=True,\n",
    "          transform=transforms.ToTensor()),\n",
    "    batch_size=4, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    MNIST(root='/tmp', download=True, train=False,\n",
    "          transform=transforms.ToTensor()),\n",
    "    batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Globals\n",
    "NUM_CLASSES = 10\n",
    "EPOCH = 2\n",
    "\n",
    "# Model\n",
    "model = CapsNet()\n",
    "\n",
    "#model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "capsule_loss = CapsuleLoss()\n",
    "\n",
    "for e in range(10):\n",
    "    # Training\n",
    "    train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for idx, (img, target) in enumerate(tqdm(train_loader, desc='Training')):\n",
    "        img = Variable(img)\n",
    "        target = Variable(index_to_one_hot(target))\n",
    "\n",
    "        \n",
    "        #img = img.cuda()\n",
    "        #target = target.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        classes, reconstructions = model(img, target) #CapsNet.forward\n",
    "\n",
    "        loss = capsule_loss(img, target, classes, reconstructions)\n",
    "        loss.backward()\n",
    "\n",
    "        train_loss += loss.data.cpu()[0]\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Training:, Avg Loss: {:.4f}'.format(train_loss))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "# ... after training, save your model f\n",
    "#model.save_state_dict('capsulestraining_'+datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")+'.pt')\n",
    "torch.save(model.state_dict(), 'capsulestraining_'+datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Testing\n",
    "correct = 0\n",
    "test_loss = 0\n",
    "\n",
    "model.eval()\n",
    "for idx, (img, target) in enumerate(tqdm(test_loader, desc='test set')):\n",
    "    img = Variable(img)\n",
    "    target_index = target\n",
    "    target = Variable(index_to_one_hot(target))\n",
    "\n",
    "    #img = img.cuda()\n",
    "    #target = target.cuda()\n",
    "\n",
    "    classes, reconstructions = model(img, target)\n",
    "\n",
    "    test_loss += margin_loss(img, target, classes, reconstructions).data.cpu()\n",
    "\n",
    "    # Get index of the max log-probability\n",
    "    pred = classes.data.max(1, keepdim=True)[1].cpu()\n",
    "    correct += pred.eq(target_index.view_as(pred)).cpu().sum()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "correct = 100. * correct / len(test_loader.dataset)\n",
    "print('Test Set: Avg Loss: {:.4f}, Accuracy: {:.4f}'.format(\n",
    "    test_loss[0], correct))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
